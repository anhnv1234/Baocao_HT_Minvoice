import time
import datetime
import pandas as pd
import re
import io
import os
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload, MediaIoBaseUpload
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request

# ==============================================================================
# 1. C·∫§U H√åNH H·ªÜ TH·ªêNG - KH√îNG C·∫¶N DANH S√ÅCH NH√ÇN VI√äN
# ==============================================================================
# ID Folder Drive c·ªßa ƒê·∫°i Ca
DRIVE_FOLDER_ID = "1056rTo3LQ9vGhjUAJMEZLUCG98DJedRC"

# ƒê·ªãnh nghƒ©a c√°c lo·∫°i d·ªØ li·ªáu c·∫ßn c√†o (T√™n file tr√™n Drive)
DATA_CONFIG = {
    "Miss_Hoi_Thoai": "convo",  # D√πng logic c√†o h·ªôi tho·∫°i
    "Miss_Zalo":      "convo",  # D√πng logic c√†o h·ªôi tho·∫°i
    "Miss_Call":      "call"    # D√πng logic c√†o cu·ªôc g·ªçi
}

SCOPES = ['https://www.googleapis.com/auth/drive']

# ==============================================================================
# 2. H√ÄM QU·∫¢N L√ù DRIVE (GI·ªÆ NGUY√äN V√å QU√Å NGON)
# ==============================================================================
def get_drive_service():
    """M·ªü c·ªïng k·∫øt n·ªëi t·ªõi kho v√†ng (Drive)."""
    creds = None
    if os.path.exists('token.json'):
        creds = Credentials.from_authorized_user_file('token.json', SCOPES)
    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
        else:
            flow = InstalledAppFlow.from_client_secrets_file('credentials.json', SCOPES)
            creds = flow.run_local_server(port=0)
        with open('token.json', 'w') as token:
            token.write(creds.to_json())
    return build('drive', 'v3', credentials=creds)

def download_file_by_name(service, file_name):
    """K√©o file v·ªÅ check h√†ng."""
    query = f"name = '{file_name}.parquet' and '{DRIVE_FOLDER_ID}' in parents and trashed = false"
    results = service.files().list(q=query, fields="files(id)").execute()
    files = results.get('files', [])

    if files:
        file_id = files[0]['id']
        request = service.files().get_media(fileId=file_id)
        fh = io.BytesIO()
        downloader = MediaIoBaseDownload(fh, request)
        done = False
        while not done:
            _, done = downloader.next_chunk()
        fh.seek(0)
        try:
            return pd.read_parquet(fh), file_id
        except:
            return pd.DataFrame(), file_id
    return pd.DataFrame(), None

def upload_to_drive(service, file_name, df, file_id=None):
    """ƒê·∫©y h√†ng n√≥ng l√™n m√¢y."""
    buffer = io.BytesIO()
    df.to_parquet(buffer, engine='pyarrow', index=False)
    buffer.seek(0)
    media = MediaIoBaseUpload(buffer, mimetype='application/octet-stream', resumable=True)
    
    try:
        if file_id:
            service.files().update(fileId=file_id, media_body=media).execute()
            print(f"      ‚úÖ [Update] {file_name} ngon cho√©t ({len(df)} d√≤ng).")
        else:
            file_metadata = {'name': f"{file_name}.parquet", 'parents': [DRIVE_FOLDER_ID]}
            service.files().create(body=file_metadata, media_body=media, fields='id').execute()
            print(f"      üÜï [New] {file_name} b√≥c tem th√†nh c√¥ng ({len(df)} d√≤ng).")
    except Exception as e:
        print(f"      üî• [L·ªñI] Toang khi upload {file_name}: {e}")

# ==============================================================================
# 3. B·ªò ƒê√îI SCRAPER: TH·ª¢ C√ÄO H·ªòI THO·∫†I & TH·ª¢ C√ÄO CALL
# ==============================================================================

# --- A. SCRAPER CHO H·ªòI THO·∫†I (Miss H·ªôi Tho·∫°i, Miss Zalo) ---
def scrape_convo_data(driver, url, type_label):
    driver.get(url)
    time.sleep(8) # Ch·ªù load h∆°i l√¢u t√≠ cho ch·∫Øc c·ªëp
    scraped_data = []
    total_items = 0
    
    try:
        pagination_text_el = driver.find_element(By.XPATH, "//*[contains(text(), 'trong t·ªïng s·ªë')]")
        match = re.search(r"t·ªïng s·ªë\s+(\d+)", pagination_text_el.text)
        if match: total_items = int(match.group(1))
    except: pass

    if total_items == 0: return []

    while True:
        try:
            scroll = driver.find_element(By.CSS_SELECTOR, ".scroll-table-wrapper")
            driver.execute_script("arguments[0].scrollTop = arguments[0].scrollHeight", scroll)
            time.sleep(1.5)
            
            rows = driver.find_elements(By.CSS_SELECTOR, "table.scroll-table tbody tr")
            if not rows: rows = driver.find_elements(By.CSS_SELECTOR, "table.scroll-table tr")
            
            for row in rows:
                try:
                    # L·∫•y t√™n kh√°ch
                    user = row.find_element(By.CSS_SELECTOR, "span.ml-3").text.strip()
                    if not user: continue
                    
                    # L·∫•y tags
                    tags = ", ".join([t.text.strip() for t in row.find_elements(By.CSS_SELECTOR, ".convo_tag__title")])
                    
                    # L·∫•y k√™nh (Channel) - C·ªôt icon th∆∞·ªùng n·∫±m ·ªü td s·ªë 2 ho·∫∑c 3, check ƒë·∫°i
                    try: 
                        cols = row.find_elements(By.TAG_NAME, "td")
                        channel_icon = cols[1].find_element(By.TAG_NAME, "i").get_attribute("class")
                    except: channel_icon = "N/A"

                    # Th·ªùi gian
                    created_time = row.find_element(By.XPATH, ".//td[last()]//span[@title]").get_attribute("title")
                    
                    item = {
                        "Lo·∫°i": type_label,
                        "Kh√°ch h√†ng": user,
                        "Tags": tags,
                        "Channel_Code": channel_icon,
                        "Th·ªùi gian": created_time
                    }
                    if item not in scraped_data: scraped_data.append(item)
                except: continue
        except: break

        if len(scraped_data) >= total_items: break
        try:
            next_btn = driver.find_element(By.CSS_SELECTOR, ".lead-actions__paginate button:last-child")
            if next_btn.get_attribute("disabled"): break 
            driver.execute_script("arguments[0].click();", next_btn)
            time.sleep(3)
        except: break
    return scraped_data

# --- B. SCRAPER CHO CU·ªòC G·ªåI (Miss Call) ---
def scrape_call_missed(driver, url, type_label):
    driver.get(url)
    time.sleep(6)
    scraped_data = []
    total_items = 0
    
    try:
        pagination_text_el = driver.find_element(By.XPATH, "//*[contains(text(), 'trong t·ªïng s·ªë')]")
        match = re.search(r"t·ªïng s·ªë\s+(\d+)", pagination_text_el.text)
        if match: total_items = int(match.group(1))
    except: pass

    if total_items == 0: return []

    while True:
        try:
            scroll = driver.find_element(By.CSS_SELECTOR, ".scroll-table-wrapper")
            driver.execute_script("arguments[0].scrollTop = arguments[0].scrollHeight", scroll)
            time.sleep(1.5)
            
            rows = driver.find_elements(By.CSS_SELECTOR, "table.scroll-table tbody tr")
            if not rows: rows = driver.find_elements(By.CSS_SELECTOR, "table.scroll-table tr")
            
            for row in rows:
                try:
                    cols = row.find_elements(By.TAG_NAME, "td")
                    if len(cols) < 5: continue 

                    # 1. SƒêT
                    try: sdt = cols[1].text.strip()
                    except: sdt = "N/A"

                    # 2. Tr·∫°ng th√°i (th∆∞·ªùng l√† Missed Call)
                    try: trang_thai = cols[2].text.strip()
                    except: trang_thai = "N/A"

                    # 3. Th·ªùi gian t·∫°o
                    try:
                        time_span = cols[7].find_element(By.TAG_NAME, "span")
                        created_time = time_span.get_attribute("title")
                    except: 
                        # Fallback n·∫øu c·ªôt l·ªách
                        try: created_time = row.find_element(By.XPATH, ".//td[last()]//span[@title]").get_attribute("title")
                        except: created_time = "N/A"

                    item = {
                        "SDT": sdt,
                        "Tr·∫°ng th√°i": trang_thai,
                        "Th·ªùi gian t·∫°o": created_time,
                        "Lo·∫°i b√°o c√°o": type_label
                    }
                    if item not in scraped_data: scraped_data.append(item)
                except: continue
        except: break

        if len(scraped_data) >= total_items: break
        try:
            next_btn = driver.find_element(By.CSS_SELECTOR, ".lead-actions__paginate button:last-child")
            if next_btn.get_attribute("disabled"): break 
            driver.execute_script("arguments[0].click();", next_btn)
            time.sleep(3)
        except: break
    return scraped_data

# ==============================================================================
# 4. LOGIC CHECK NG√ÄY M·ªöI (FAST & FURIOUS)
# ==============================================================================
def get_global_start_date(service):
    """
    Check 1 file ƒë·∫°i di·ªán (Miss_Hoi_Thoai), th·∫•y ng√†y n√†o th√¨ ch·ªët lu√¥n.
    """
    default_date = datetime.date(2026, 1, 1)
    print("\nüîç ƒê·ªá ƒëang check nhanh Drive...")

    # Check th·ª≠ file ƒë·∫ßu ti√™n trong list
    check_key = list(DATA_CONFIG.keys())[0] # "Miss_Hoi_Thoai"
    print(f"   üëÄ Ng√≥ qua file: {check_key}...", end=" ")
    
    df, _ = download_file_by_name(service, check_key)
    
    if not df.empty and 'Ngay_C√†o' in df.columns:
        try:
            dates = pd.to_datetime(df['Ngay_C√†o'], format="%Y-%m-%d", errors='coerce').dt.date
            dates = dates.dropna()
            
            if not dates.empty:
                local_max = dates.max()
                print(f"‚úÖ Th·∫•y ng√†y Max: {local_max}")
                start_date = local_max + datetime.timedelta(days=1)
                print(f"üéØ => CH·ªêT H·∫†: C√†y ti·∫øp t·ª´ ng√†y: {start_date}\n")
                return start_date
            else:
                print("‚ùå File c√≥ nh∆∞ng l·ªói ng√†y.")
        except:
            print("‚ùå L·ªói format ng√†y.")
    else:
        print("‚ùå Ch∆∞a c√≥ file n√†o c·∫£.")

    print(f"‚ö†Ô∏è => Drive s·∫°ch bong, b·∫Øt ƒë·∫ßu c√†y t·ª´ ƒë·∫ßu: {default_date}\n")
    return default_date

# ==============================================================================
# 5. MAIN PROGRAM
# ==============================================================================
def main():
    print("üöÄ MISS REPORT SCRAPER - CHUY√äN TR·ªä DATA B·ªä S√ìT")
    service = get_drive_service()
    
    # 1. Check ng√†y
    curr_date = get_global_start_date(service)
    yesterday = datetime.date.today() - datetime.timedelta(days=1)
    
    if curr_date > yesterday:
        print("üòé D·ªØ li·ªáu Miss ƒë√£ update full r·ªìi ƒê·∫°i Ca ∆°i!")
        return

    # 2. B·∫≠t Chrome
    options = Options()
    options.add_experimental_option("debuggerAddress", "127.0.0.1:9222")
    try:
        driver = webdriver.Chrome(options=options)
    except:
        print("üî• L·ªói: ƒê·∫°i ca nh·ªõ b·∫≠t Chrome Debugger port 9222 nh√©!")
        return

    # 3. V√≤ng l·∫∑p
    while curr_date <= yesterday:
        day_str = curr_date.strftime("%Y-%m-%d")
        print(f"üìÖ --- ƒêANG C√ÄY DATA MISS NG√ÄY: {day_str} ---")
        
        # T√≠nh to√°n ID th·ªùi gian Subiz (C√¥ng th·ª©c th·∫ßn th√°nh)
        diff_days = (curr_date - datetime.date(2026, 1, 1)).days
        start_val = 490889 + (diff_days * 24)
        t_range = f"{start_val},{start_val + 23}"
        
        daily_storage = {k: [] for k in DATA_CONFIG.keys()}

        # --- X·ª¨ L√ù T·ª™NG LO·∫†I URL ---
        
        # 1. MISS H·ªòI THO·∫†I
        print("   üîç Qu√©t Miss H·ªôi Tho·∫°i...")
        url_hoi_thoai = f"https://app.subiz.com.vn/new-reports/convo-list?conditions=%5B%7B%22key%22%3A%22created_time%22,%22value%22%3A%22%5B{t_range}%5D%22%7D,%7B%22key%22%3A%22channel%22,%22value%22%3A%22%5B%5C%22email%5C%22,%5C%22subiz%5C%22,%5C%22facebook%5C%22,%5C%22facebook_comment%5C%22,%5C%22instagram%5C%22,%5C%22instagram_comment%5C%22,%5C%22form%5C%22,%5C%22google_review%5C%22%5D%22%7D,%7B%22key%22%3A%22agent_sent%22,%22value%22%3A%22%5B%5C%22no%5C%22%5D%22%7D,%7B%22key%22%3A%22tags%22,%22value%22%3A%22%5B%5C%22yes%5C%22,%5C%22tgrzpqjrknqhxliqelct%5C%22%5D%22%7D%5D"
        items_ht = scrape_convo_data(driver, url_hoi_thoai, "Miss_Hoi_Thoai")
        if items_ht: 
            for x in items_ht: x["Ngay_C√†o"] = day_str
            daily_storage["Miss_Hoi_Thoai"].extend(items_ht)

        # 2. MISS ZALO
        print("   üîç Qu√©t Miss Zalo...")
        url_zalo = f"https://app.subiz.com.vn/new-reports/convo-list?conditions=%5B%7B%22key%22%3A%22created_time%22,%22value%22%3A%22%5B{t_range}%5D%22%7D,%7B%22key%22%3A%22channel%22,%22value%22%3A%22%5B%5C%22zalo_personal%5C%22,%5C%22zalo%5C%22%5D%22%7D,%7B%22key%22%3A%22agent_sent%22,%22value%22%3A%22%5B%5C%22no%5C%22%5D%22%7D,%7B%22key%22%3A%22tags%22,%22value%22%3A%22%5B%5C%22yes%5C%22,%5C%22tgrzpqjrknqhxliqelct%5C%22%5D%22%7D%5D"
        items_zl = scrape_convo_data(driver, url_zalo, "Miss_Zalo")
        if items_zl:
            for x in items_zl: x["Ngay_C√†o"] = day_str
            daily_storage["Miss_Zalo"].extend(items_zl)

        # 3. MISS CALL
        print("   üîç Qu√©t Miss Call...")
        url_call = f"https://app.subiz.com.vn/new-reports/call-list?conditions=%5B%7B%22key%22%3A%22created_time%22%2C%22value%22%3A%22%5B{t_range}%5D%22%7D%2C%7B%22key%22%3A%22missed_call%22%7D%5D"
        items_call = scrape_call_missed(driver, url_call, "Miss_Call")
        if items_call:
            for x in items_call: x["Ngay_C√†o"] = day_str
            daily_storage["Miss_Call"].extend(items_call)

        # --- SAVE TO DRIVE ---
        print(f"\nüì¶ [GOM H√ÄNG] Xong ng√†y {day_str}. ƒê·∫©y l√™n Drive...")
        for key in DATA_CONFIG.keys():
            if daily_storage[key]:
                df_old, f_id = download_file_by_name(service, key)
                new_df = pd.DataFrame(daily_storage[key])
                final_df = pd.concat([df_old, new_df], ignore_index=True)
                upload_to_drive(service, key, final_df, f_id)
            else:
                pass # Kh√¥ng c√≥ data th√¨ im l·∫∑ng l√† v√†ng

        curr_date += datetime.timedelta(days=1)

    print("\nüíé MISSION COMPLETED! ƒê·∫°i ca ƒë·∫πp trai v√¥ ƒë·ªëi!")

if __name__ == "__main__":
    main()